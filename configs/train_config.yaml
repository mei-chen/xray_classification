# =============================================================================
# Chest X-Ray Classification Training Configuration
# =============================================================================
# All hyperparameters and settings for reproducible training runs

# Random seed for reproducibility
seed: 42

# Data configuration
data:
  # Path to the dataset (pre-split with train/val/test folders)
  raw_data_path: "data/raw/chest-xray-dataset"
  processed_data_path: "data/processed"
  
  # Image settings
  image_size: 224
  num_channels: 3
  
  # Class labels
  classes:
    - "Normal"
    - "Pneumonia"
    - "Tuberculosis"
  num_classes: 3
  
  # Data split ratios
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15
  
  # Dataloader settings
  batch_size: 32
  num_workers: 4
  pin_memory: true

# Data augmentation configuration
# Based on ablation study results:
#   - brightness_only: +2.8% (best single augmentation)
#   - hflip_only: +2.2%
#   - contrast_only: +1.6%
#   - rotation_only: -0.5% (hurts performance)
#   - full_augmentation: -0.2% (too aggressive)
augmentation:
  # Training augmentations (optimized based on ablation)
  train:
    horizontal_flip: true          # +2.2% improvement
    rotation_degrees: 10           # Reduced from 15 (rotation hurts)
    brightness_range: [0.8, 1.2]   # +2.8% improvement (best)
    contrast_range: [0.8, 1.2]     # +1.6% improvement
    random_crop: true
    # CLAHE (Contrast Limited Adaptive Histogram Equalization)
    # Helps with low-contrast images, especially TB class (14% low-contrast vs 2-3% for others)
    clahe_probability: 0.2  # Apply to 20% of training images
    normalize:
      mean: [0.485, 0.456, 0.406]  # ImageNet stats
      std: [0.229, 0.224, 0.225]
  
  # Validation/Test augmentations (only resize and normalize)
  eval:
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

# Model configuration
model:
  # Architecture: efficientnet_b0, efficientnet_b1, resnet50, etc.
  architecture: "efficientnet_b0"
  
  # Use pretrained weights from ImageNet
  pretrained: true
  
  # Freeze backbone initially for transfer learning
  freeze_backbone: true
  unfreeze_at_epoch: 5  # Unfreeze after N epochs
  
  # Classification head
  dropout: 0.3
  use_bn_before_classifier: true

# Training configuration
training:
  # Number of epochs
  epochs: 50
  
  # Optimizer settings
  optimizer:
    name: "adamw"
    learning_rate: 0.001
    weight_decay: 0.01
    betas: [0.9, 0.999]
    # Differential learning rate: backbone LR = learning_rate * backbone_lr_factor
    # Lower factor means backbone learns slower (preserves pretrained features)
    backbone_lr_factor: 0.1  # 10x lower LR for backbone when unfreezing
  
  # Learning rate scheduler
  scheduler:
    name: "cosine_warmup"
    warmup_epochs: 3
    min_lr: 0.00001
  
  # Loss function
  loss:
    name: "cross_entropy"
    label_smoothing: 0.1
    use_class_weights: true  # Handle class imbalance
  
  # Mixed precision training
  use_amp: true
  
  # Gradient clipping
  gradient_clip_val: 1.0
  
  # Smart early stopping with optimal model detection
  early_stopping:
    enabled: true
    patience: 10                  # Stop if no improvement for N epochs
    min_delta: 0.001              # Minimum improvement to count as progress
    monitor: "val_f1"
    mode: "max"
    # Advanced stopping criteria
    overfitting_patience: 5       # Stop if overfitting detected for N epochs
    overfitting_threshold: 0.05   # Gap threshold to consider overfitting (5%)
    convergence_threshold: 0.002  # Std dev threshold for convergence detection
    convergence_window: 5         # Window size for convergence check
  
  # Model checkpointing
  checkpoint:
    save_top_k: 3
    monitor: "val_f1"
    mode: "max"
    save_last: true

# Paths
paths:
  model_dir: "models"
  reports_dir: "reports"
  figures_dir: "reports/figures"
  logs_dir: "logs"

# Hardware
device: "auto"  # "auto", "cuda", "mps", "cpu"

# Logging
logging:
  level: "INFO"
  log_every_n_steps: 10
  save_predictions: true

